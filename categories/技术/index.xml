<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>技术 on 多少光年</title>
    <link>http://tietang.wang/categories/%E6%8A%80%E6%9C%AF/</link>
    <description>Recent content in 技术 on 多少光年</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 18 Nov 2016 19:22:47 +0000</lastBuildDate><atom:link href="http://tietang.wang/categories/%E6%8A%80%E6%9C%AF/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hystrix semaphore和thread隔离策略的区别及配置参考</title>
      <link>http://tietang.wang/posts/hystrix/hystrix-semaphore%E5%92%8Cthread%E9%9A%94%E7%A6%BB%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Fri, 18 Nov 2016 19:22:47 +0000</pubDate>
      
      <guid>http://tietang.wang/posts/hystrix/hystrix-semaphore%E5%92%8Cthread%E9%9A%94%E7%A6%BB%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
      <description>Hystrix semaphore和thread隔离策略的区别及配置参考 通用设置说明 Hystrix所有的配置都是hystrix.command.[HystrixCommandKey]开头,其中[HystrixCommandKey]是可变的，默认是default,即hystrix.command.default；另外Hystrix内置了默认参数，如果没有配置Hystrix属性，默认参数就会被设置，其优先级： hystrix.command.[HystrixCommandKey].XXX hystrix.command.default.XXX Hystrix代码内置属性参数值 Hystrix隔离策略相关的参数 策略参数设置 execution.isolation.strategy= THREAD|SEMAPHORE execution.isolation.thread.timeoutInMilliseconds hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds 用来设置thread和semaphore两种隔离策略的超时时间，默认值是1000。 建议设置这个参数，在Hystrix 1.4.0之前，semaphore-isolated隔离策略是不能超时的，从1.4.0开始semaphore-isolated也支持超时时间了。 建议通过CommandKey设置不同微服务的超时时间,对于</description>
    </item>
    
    <item>
      <title>zuul 参数调优</title>
      <link>http://tietang.wang/posts/hystrix/zuu%E5%8F%82%E6%95%B0l%E4%BC%98%E5%8C%96%E5%92%8C%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Thu, 17 Nov 2016 19:22:47 +0000</pubDate>
      
      <guid>http://tietang.wang/posts/hystrix/zuu%E5%8F%82%E6%95%B0l%E4%BC%98%E5%8C%96%E5%92%8C%E9%85%8D%E7%BD%AE/</guid>
      <description>zuul 参数调优 适用版本： spring-boot: 1.4.x.RELEASE spring-cloud：Camden.SR3 Hystrix: 1.5.6 spring-boot-tomcat 优化参数： 主要只有2个，最大和最小worker线程： 1 2 server.tomcat.max-threads=128 # Maximum amount of worker threads. server.tomcat.min-spare-threads=64 # Minimum amount of worker threads. spring-boot-undertow 优化参数： ioThreads 设置IO线程数, 它主要执行非阻塞的任务,它们会负责多个连接,默认取CPU核心数量,最小值为2。 Math.max(Runtime.getRuntime().availableProcessors(), 2); spring-boot 参数：server.undertow.io-threads= worker-threads 阻塞任务线程池, 当执行类似servlet请求阻塞操作, undertow会从这个线程池中取得线程,它的值设置取决于系统的负载，默认值为io-threads*8。 spring-boot 参数：server.undertow.worker-threads= buffer buffer-size: 每块buffer的空间大小,越小的空间被利用越充分。 **buffers-per-region: ** 每个区分配的buffer数量 , 所以pool的大小是buffer-size * buffers-per-region。 directBuffers 是否分配的直接内存。 获取JVM最大可用内存maxMemory=</description>
    </item>
    
    <item>
      <title>RestTemplate遇上Hystrix</title>
      <link>http://tietang.wang/posts/hystrix/resttemplate%E9%81%87%E4%B8%8Ahystrix/</link>
      <pubDate>Fri, 02 Sep 2016 09:20:00 +0000</pubDate>
      
      <guid>http://tietang.wang/posts/hystrix/resttemplate%E9%81%87%E4%B8%8Ahystrix/</guid>
      <description>RestTemplate遇上Hystrix RestTemplate集成Hystrix和Robbin 查看RestTemplate源代码，可以看到RestTemplate继承了InterceptingHttpAccessor类，InterceptingHttpAccessor类通过ClientHttpRequestInterceptor接口提供了扩展功能。 实现intercept方法，在该方法中封装HystrixCommand和Ribbon逻辑即可。 下面的代码是集成了HystrixCommand的例子： 1 2 3 4 5 6 7 8 9 10 11 12 13 @Override public ClientHttpResponse intercept( final HttpRequest request, final byte[] body, final ClientHttpRequestExecution execution) throws IOException { final URI originalUri = request.getURI(); String serviceName = mapCommandKey(originalUri); log.info(&amp;#34;{} :{} {} &amp;#34;, serviceName, request.getMethod().name(), originalUri.toString()); return new RestTemplateHystrixCommnad(serviceName, () -&amp;gt; { return execution.execute(request, body); }, hystrixFallback).execute(); } 下面是集成了HystrixCommand和Ribbon的例子 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Override public ClientHttpResponse intercept( final HttpRequest request, final byte[] body, final ClientHttpRequestExecution execution) throws IOException { final URI originalUri = request.getURI(); String serviceName = mapCommandKey(originalUri); log.info(&amp;#34;{} :{} {} &amp;#34;, serviceName, request.getMethod().name(), originalUri.toString()); return new RestTemplateHystrixCommnad(serviceName, () -&amp;gt; { return this.loadBalancer.execute(serviceName, instance -&amp;gt; { HttpRequest</description>
    </item>
    
    <item>
      <title>软件开发中的单一职责</title>
      <link>http://tietang.wang/posts/%E6%8A%80%E6%9C%AF/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E4%B8%AD%E7%9A%84%E5%8D%95%E4%B8%80%E8%81%8C%E8%B4%A3/</link>
      <pubDate>Tue, 28 Jun 2016 09:06:33 +0000</pubDate>
      
      <guid>http://tietang.wang/posts/%E6%8A%80%E6%9C%AF/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E4%B8%AD%E7%9A%84%E5%8D%95%E4%B8%80%E8%81%8C%E8%B4%A3/</guid>
      <description>软件开发中的单一职责 最近在实践微服务化过程中，对其“单一职责”原则深有体会。 那么只有微服务化才可以单一职责，才可以解耦吗？答案是否定的。 单一职责原则是这样定义的：单一的功能，并且完全封装起来。 我们做后端Java开发的，应该最熟悉的就是标准的3层架构了，尤其是使用Spring.io体系的：Controller，Service，Dao/Repository。为什么要分层？就是为了保证单一职责，数据模型的事情交给Controller，业务逻辑的事情交给Service，和数据打交道的事情就交给Dao/Repository。有时候或者有些人会分层分的更多，4层，5层，我自己也这样干过，说白了也是为了保证单一职责，3层不能满足单一职责了，耦合度高了，就分。 我们都知道一个webapp在经过一定时间的开发后，就惨不忍睹，即便是有标准的分层，页面或模板文件一大堆，最初的很清晰的3层标准架构也变味了，Cont</description>
    </item>
    
    <item>
      <title>负载均衡之加权轮询算法</title>
      <link>http://tietang.wang/posts/%E6%8A%80%E6%9C%AF/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E4%B9%8B%E5%8A%A0%E6%9D%83%E8%BD%AE%E8%AF%A2%E7%AE%97%E6%B3%95/</link>
      <pubDate>Thu, 16 Jun 2016 09:06:33 +0000</pubDate>
      
      <guid>http://tietang.wang/posts/%E6%8A%80%E6%9C%AF/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E4%B9%8B%E5%8A%A0%E6%9D%83%E8%BD%AE%E8%AF%A2%E7%AE%97%E6%B3%95/</guid>
      <description>负载均衡之加权轮询算法 算法举例说明 服务实例 权重 127.0.0.1:8001 1 127.0.0.1:8002 2 127.0.0.1:8003 3 共有三个实例，总权重为6，那么实现效果应该为每调用6次： 每个实例应该被调用权重次数 权重数大的优先被调用 根据以上说明，那么进行排列组合： 先按照权重大小排序 把权重数做为调用次数排列 排列的结果是这样的： 序号 服务实例 权重 1 127.0.0.1:8003 3 2 127.0.0.1:8003 3 3 127.0.0.1:8003 3 4 127.0.0.1:8002 2 5 127.0.0.1:8002 2 6 127.0.0.1:8001 1 貌似没问题，但每个实例调用不是交替的，分布不够均匀，改进一下重新排列组合： 序号 服务实例 权重 1 127.0.0.1:8003 3 2 127.0.0.1:8002 2 3 127.0.0.1:8003 3 4 127.0.0.1:8002 2 5 127.0.0.1:8003 3 6 127.0.0.1:8001 1 或者 序号 服务实例 权重 1 127.0.0.1:8003 3 2 127.0.0.1:8002 2 3 127.0.0.1:8003 3 4 127.0.0.1:8001 1 5 127.0.0.1:8003 3 6 127.0.0.1:8002 2 2个权重变量：weight，current_weight weight 配置的固定不变的权重 current_weight 会动态调整的权重，初始化为0，运行时动态调整。 选取开始时，先重新调整current_weight= current_weight+weight，然后通过current_weight值从大到小排序，选择current_weight值最大</description>
    </item>
    
    <item>
      <title>Hystrix简介</title>
      <link>http://tietang.wang/posts/hystrix/hystrix%E7%AE%80%E4%BB%8B/</link>
      <pubDate>Wed, 09 Mar 2016 09:22:47 +0000</pubDate>
      
      <guid>http://tietang.wang/posts/hystrix/hystrix%E7%AE%80%E4%BB%8B/</guid>
      <description>What Is Hystrix? What Is Hystrix For? What Problem Does Hystrix Solve? What Design Principles Underlie Hystrix? How Does Hystrix Accomplish Its Goals? 在分布式环境中，不可避免的有许多服务依赖，而且有时候一些服务会失败。Hystrix library通过添加延迟容忍和容错逻辑来控制分布式服务之间的相互影响。Hystrix通过服务之间访问的隔离点阻止连锁故障，并提供了失败回退机制（fallback），来改进系统服务的弹性。 Hystrix的历史 Hystrix是在2011年由Netflix API 团队的弹性工程演变而来。在2012年，Hystrix日益完善和成熟，在Netflix的许多团队也开始采用。现在，在Netflix，每天有成千上万的线程隔离和数百亿的信号隔离被调用执行。这已经在可用性和弹性上产生了很大的改进。 下面的链接提供了围绕Hystrix和挑战，试图解决： “Making Netflix API More Resilient” “Fault Tolerance in a High Volume, Distributed System” “Performance and Fault Tolerance for the Netflix API” “Applicati</description>
    </item>
    
    <item>
      <title>Hystrix降级模式总结</title>
      <link>http://tietang.wang/posts/hystrix/hystrix%E9%99%8D%E7%BA%A7%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/</link>
      <pubDate>Wed, 09 Mar 2016 09:22:47 +0000</pubDate>
      
      <guid>http://tietang.wang/posts/hystrix/hystrix%E9%99%8D%E7%BA%A7%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/</guid>
      <description>失败回退降级模式 失败回退需要实现HystrixCommand.getFallback方法或者HystrixObservableCommand. HystrixObservableCommand()方法。 快速失败Fail Fast 如果业务异常，就抛出一个异常 静默失败Fail Silent 失败时返回一个空response或者移除业务功能，例如返回null，空字符串，空map，空list等 Fallback: Static 失败时，返回默认值来替代引起失败的原因 Fallback: Stubbed 返回替代值，还没理解 Fallback: Cache via Network 当后端服务失败时，从网络缓存获取返回值 Primary + Secondary with Fallback 故障转移，当主服务失败时，调用从服务。当从服务也失败时结合其他模式 Client Doesn’t Perform Network Access * Get-Set-Get with Request Cache Invalidation</description>
    </item>
    
    <item>
      <title>wrk基准测试工具安装使用</title>
      <link>http://tietang.wang/posts/%E6%8A%80%E6%9C%AF/%E5%B7%A5%E5%85%B7/wrk%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Fri, 04 Mar 2016 09:06:33 +0000</pubDate>
      
      <guid>http://tietang.wang/posts/%E6%8A%80%E6%9C%AF/%E5%B7%A5%E5%85%B7/wrk%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/</guid>
      <description>git https://github.com/wg/wrk git clone https://github.com/wg/wrk.git 安装 在makefile中33行 LDIR = deps/luajit/src LIBS := -lluajit $(LIBS) CFLAGS += -I$(LDIR) LDFLAGS += -L$(LDIR) 下面添加： LDFLAGS += -L/usr/local/opt/openssl/lib CFLAGS += -I/usr/local/opt/openssl/include make 基本使用 Basic Usage wrk -t12 -c400 -d30s http://127.0.0.1:8080/index.html This runs a benchmark for 30 seconds, using 12 threads, and keeping 400 HTTP connections open. Output: 1 2 3 4 5 6 7 8 Running 30s test @ http://127.0.0.1:8080/index.html 12 threads and 400 connections Thread Stats Avg Stdev Max +/- Stdev Latency 635.91us 0.89ms 12.92ms 93.69% Req/Sec 56.20k 8.07k 62.00k 86.54% 22464657 requests in 30.00s, 17.76GB read Requests/sec: 748868.53 Transfer/sec: 606.33MB 参数说明 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 $ wrk Usage: wrk &amp;lt;options&amp;gt; &amp;lt;url&amp;gt; Options: -c, --connections &amp;lt;N&amp;gt; Connections to keep open -d, --duration &amp;lt;T&amp;gt; Duration of test -t, --threads &amp;lt;N&amp;gt; Number of threads to use -s, --script &amp;lt;S&amp;gt; Load Lua script file -H, --header &amp;lt;H&amp;gt; Add header to request --latency Print latency statistics --timeout &amp;lt;T&amp;gt; Socket/request timeout -v, --version Print version details Numeric arguments may include a SI unit (1k, 1M, 1G) Time arguments may include a time unit (2s, 2m, 2h)</description>
    </item>
    
    <item>
      <title>Hystrix 参数详解</title>
      <link>http://tietang.wang/posts/hystrix/hystrix%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/</link>
      <pubDate>Thu, 25 Feb 2016 09:20:00 +0000</pubDate>
      
      <guid>http://tietang.wang/posts/hystrix/hystrix%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/</guid>
      <description>hystrix.command.default和hystrix.threadpool.default中的default为默认CommandKey Command Properties Execution相关的属性的配置： hystrix.command.default.execution.isolation.strategy 隔离策略，默认是Thread, 可选Thread｜Semaphore thread 通过线程数量来限制并发请求数，可以提供额外的保护，但有一定的延迟。一般用于网络调用 semaphore 通过semaphore count来限制并发请求数，适用于无网络的高并发请求 hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds 命令执行超时时间，默认1000ms hystrix.command.default.execution.timeout.enabled 执行是否启用超时，默认启用true hystrix.command.default.execution.isolation.thread.interruptOnTimeout 发生超时是是否中断，默认true hystrix.command.default.execution.isolation.semaphore.maxConcurrentRequests 最大并发请求数，默认10，该参数当使用ExecutionIsolationStrategy.SEMAPHORE策略时才有效。如果达到最大并发请求数，请求会被拒绝。理论上选择semaphore size的原则和选择thread size一致，但选用semaphore时每次执行的单元要比</description>
    </item>
    
    <item>
      <title>Hexo命令速记</title>
      <link>http://tietang.wang/posts/%E6%8A%80%E6%9C%AF/hexo/hexo%E5%91%BD%E4%BB%A4%E9%80%9F%E8%AE%B0/</link>
      <pubDate>Sun, 21 Feb 2016 22:31:12 +0000</pubDate>
      
      <guid>http://tietang.wang/posts/%E6%8A%80%E6%9C%AF/hexo/hexo%E5%91%BD%E4%BB%A4%E9%80%9F%E8%AE%B0/</guid>
      <description>简写 1 2 3 4 5 hexo n &amp;#34;我的博客&amp;#34; == hexo new &amp;#34;我的博客&amp;#34; #新建文章 hexo p == hexo publish hexo g == hexo generate#生成 hexo s == hexo server #启动服务预览 hexo d == hexo deploy#部署 服务器 1 2 3 4 5 6 7 8 9 hexo server #Hexo 会监视文件变动并自动更新，您无须重启服务器。 hexo server -s #静态模式 hexo server -p 5000 #更改端口 hexo server -i 192.168.1.1 #自定义 IP hexo clean #清除缓存 网页正常情况下可以忽略此条命令 hexo g #生成静态网页 hexo d #开始部署 hexo d -g #部署前先生成今天网页 监视文件变动 1 2 hexo generate #使用 Hexo 生成静态文件快速而且简单 hexo generate --watch #监视文件变动 完成后部署 1 2 3 4 5 两个命令的作用是相同的 hexo generate --deploy hexo deploy --generate hexo deploy -g hexo server -g 模版 1 2 3 4 5 6 7 8 9 hexo new &amp;#34;postName&amp;#34; #新建文章 hexo new page &amp;#34;pageName&amp;#34; #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，&amp;#39;ctrl + c&amp;#39;关闭server） hexo deploy #将.deploy目录部署到GitHub hexo new [layout] &amp;lt;title&amp;gt; hexo new photo &amp;#34;My Gallery&amp;#34; hexo new &amp;#34;Hello</description>
    </item>
    
    <item>
      <title>领域模型的价值</title>
      <link>http://tietang.wang/posts/%E6%8A%80%E6%9C%AF/%E9%A2%86%E5%9F%9F%E6%A8%A1%E5%9E%8B/%E9%A2%86%E5%9F%9F%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BB%B7%E5%80%BC/</link>
      <pubDate>Sun, 21 Feb 2016 20:20:42 +0000</pubDate>
      
      <guid>http://tietang.wang/posts/%E6%8A%80%E6%9C%AF/%E9%A2%86%E5%9F%9F%E6%A8%A1%E5%9E%8B/%E9%A2%86%E5%9F%9F%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BB%B7%E5%80%BC/</guid>
      <description>价值 提供什么服务： 什么来体现服务：运行方式，运行过程和业务逻辑 提供的质量：如何服务，要做的事情 传统数据库为中心 业务逻辑在数据库上，结合系统代码来保证业务逻辑的实现。 以数据库为中心的开发如何的OO﹐如何多的设计模式﹐架构体系如何优美﹐它始终离不开数据库。 OO|面向对象 表现点则是直接在对象本身上﹐在于对象之间真正的交互过程﹐结果也是保留在对象的属性和对象与对象的关系中 逻辑直接存在于对象上﹐这与现实情况是吻合的。 领域模型是一种思维﹐是一种方法,是在系统分析阶段使用﹐而不是在代码中进行纯设计时的工具。不是为了OO而领域﹐不是为了最终要新增数据库而领域。在没有理解领域模型本质时，任何编码都得不到收益。 在分析或架构一个系统时，要得出系统的服务和服务场景，即user case。 领域模型的特点 领域模型是对具有某个边界的领域的一个抽象，反映了领域内用户业务需求的本质；领域模型是有边界的，只反应了我们在领域内所</description>
    </item>
    
    <item>
      <title>FlatBuffers 使用指南</title>
      <link>http://tietang.wang/posts/%E6%8A%80%E6%9C%AF/flatbuffers/flatbuffers%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</link>
      <pubDate>Fri, 19 Feb 2016 20:20:42 +0000</pubDate>
      
      <guid>http://tietang.wang/posts/%E6%8A%80%E6%9C%AF/flatbuffers/flatbuffers%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</guid>
      <description>FlatBuffers 使用指南 FlatBuffers序列化性能是protobuf的2倍，但size也是protobuf的2倍 编译源码 1 2 3 $ git clone https://github.com/google/flatbuffers.git #切换到最新release版本 $ git checkout v1.2.0 安装cmake http://www.cmake.org. 1 2 3 4 for mac osx $ brew install cmake for centOS $ sudo yum install cmake 用cmake构建project 1 2 3 cmake -G &amp;#34;Unix Makefiles&amp;#34; cmake -G &amp;#34;Visual Studio 10&amp;#34; cmake -G &amp;#34;Xcode&amp;#34; 在*nix系统，mac osx系统也建议使用 cmake -G &amp;quot;Unix Makefiles&amp;quot;，生成Makefile,之后make &amp;amp; make install 编译生成flatc并安装到系统。 1 2 3 $ cmake -G &amp;#34;Unix Makefiles&amp;#34; $ make $ make insall 使用schema编译器flatc来生成基础代码 1 2 3 $ cd samples #在目录src中生成java代码 $flatc -j -o src monster.fbs 编程语言参数: &amp;ndash;cpp, -c : Generate a C++ header for all definitions in this file (as filename_generated.h). &amp;ndash;java, -j : Generate Java code. &amp;ndash;csharp, -n : Generate C# code. &amp;ndash;go, -g : Generate Go code. &amp;ndash;python, -p: Generate Python code. &amp;ndash;javascript, -s: Generate JavaScript code. &amp;ndash;php: Generate PHP code. 其他常用选项： -o PATH 指定源码输出目录 -I PATH 有include语句时，指定include目录 完整的参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22</description>
    </item>
    
    <item>
      <title>FlatBuffers简介</title>
      <link>http://tietang.wang/posts/%E6%8A%80%E6%9C%AF/flatbuffers/flatbuffers%E7%AE%80%E4%BB%8B/</link>
      <pubDate>Fri, 19 Feb 2016 20:20:42 +0000</pubDate>
      
      <guid>http://tietang.wang/posts/%E6%8A%80%E6%9C%AF/flatbuffers/flatbuffers%E7%AE%80%E4%BB%8B/</guid>
      <description>FlatBuffers简介 代码：https://github.com/google/flatbuffers/ 文档：http://google.github.io/flatbuffers/ FlatBuffers是一个开源的、跨平台的、高效的、提供了C++/Java接口的序列化工具库。它是Google专门为游戏开发或其他性能敏感的应用程序需求而创建。 允许在不解析和解包就可以直接访问序列化数据，而且仍然很好地向上和向下兼容，这意味着序列化对象可以多版本共存。 支持的操作系统 Android Windows MacOS X Linux 目前支持的编程语言 C++ C# Go Java JavaScript PHP Python and many more in progress&amp;hellip; 为什么要用FlatBuffers? 对序列化数据的访问不需要打包和拆包——它将序列化数据存储在缓存中，这些数据既可以存储在文件中，又可以通过网络原样传输，而没有任何解析开销； 内存效率和速度——访问数据时的唯一内存需求就是缓冲区，不需要额外的内存分配。 这里可查看详细的基准测试； 扩展</description>
    </item>
    
  </channel>
</rss>
